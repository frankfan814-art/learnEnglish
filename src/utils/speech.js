/**
 * è¯­éŸ³åˆæˆå·¥å…· - æ”¹è¿›ç‰ˆ
 * æ”¯æŒå¤šç§æ’­æ”¾æ–¹å¼å’Œé™çº§ç­–ç•¥ï¼Œé’ˆå¯¹ç§»åŠ¨ç«¯ä¼˜åŒ–
 */

// æ’­æ”¾å™¨å®ä¾‹
let audioRef = null
let audioElementRef = null
let audioUnlocked = false

// æ£€æµ‹æµè§ˆå™¨èƒ½åŠ›
const detectCapabilities = () => {
  const ua = navigator.userAgent || ''
  const isAndroid = /Android/i.test(ua)
  const isXiaomi = /xiaomi|redmi|mi\s+/i.test(ua)
  const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(ua)

  // æ£€æµ‹éŸ³é¢‘æ ¼å¼æ”¯æŒ
  const audio = document.createElement('audio')
  const supportsMP3 = !!(audio.canPlayType && audio.canPlayType('audio/mpeg').replace(/no/, ''))
  const supportsWAV = !!(audio.canPlayType && audio.canPlayType('audio/wav').replace(/no/, ''))
  const supportsWebM = !!(audio.canPlayType && audio.canPlayType('audio/webm').replace(/no/, ''))

  return {
    isAndroid,
    isXiaomi,
    isMobile,
    supportsMP3,
    supportsWAV,
    supportsWebM
  }
}

const caps = detectCapabilities()

/**
 * è§£é”ç§»åŠ¨ç«¯éŸ³é¢‘æ’­æ”¾ï¼ˆéœ€åœ¨ç”¨æˆ·äº¤äº’äº‹ä»¶ä¸­è°ƒç”¨ï¼‰
 */
const unlockAudio = async () => {
  if (!caps.isMobile) {
    return true
  }

  // ä¼˜å…ˆä½¿ç”¨ Web Audio è§£é”
  try {
    const AudioContextClass = window.AudioContext || window.webkitAudioContext
    if (AudioContextClass) {
      const ctx = new AudioContextClass()
      if (ctx.state === 'suspended') {
        await ctx.resume()
      }
      const buffer = ctx.createBuffer(1, 1, 22050)
      const source = ctx.createBufferSource()
      source.buffer = buffer
      source.connect(ctx.destination)
      source.start(0)
      source.stop(0)
      if (ctx.state !== 'closed') {
        await ctx.close()
      }
      return true
    }
  } catch (error) {
    console.warn('[TTS] Web Audio è§£é”å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ:', error)
  }

  // å¤‡ç”¨ï¼šæ’­æ”¾ä¸€æ®µé™éŸ³éŸ³é¢‘
  try {
    const silentAudio = document.createElement('audio')
    silentAudio.src = 'data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEAESsAACJWAAACABAAZGF0YQAAAAA='
    silentAudio.muted = true
    silentAudio.setAttribute('webkit-playsinline', 'true')
    silentAudio.setAttribute('playsinline', 'true')
    const playPromise = silentAudio.play()
    if (playPromise !== undefined) {
      await playPromise.catch(() => {})
    }
    silentAudio.pause()
    silentAudio.remove()
    return true
  } catch (error) {
    console.warn('[TTS] é™éŸ³éŸ³é¢‘è§£é”å¤±è´¥:', error)
  }

  return false
}

/**
 * æ¸…ç†éŸ³é¢‘èµ„æº
 */
const cleanup = () => {
  if (audioRef) {
    audioRef.pause()
    audioRef = null
  }
  if (audioElementRef) {
    audioElementRef.pause()
    audioElementRef.src = ''
    audioElementRef.load()
    audioElementRef.remove()
    audioElementRef = null
  }
}

/**
 * æ’­æ”¾æ–¹å¼ 1: ä½¿ç”¨ Blob URL (é€‚ç”¨äºå¤§å¤šæ•°ç°ä»£æµè§ˆå™¨)
 */
const playWithBlob = async (audioBuffer, mimeType) => {
  return new Promise((resolve, reject) => {
    try {
      cleanup()

      const audioBlob = new Blob([audioBuffer], { type: mimeType })
      const audioUrl = URL.createObjectURL(audioBlob)

      audioRef = new Audio(audioUrl)
      audioRef.preload = 'auto'
      audioRef.setAttribute('webkit-playsinline', 'true')
      audioRef.setAttribute('playsinline', 'true')

      audioRef.onended = () => {
        URL.revokeObjectURL(audioUrl)
        audioRef = null
        resolve()
      }

      audioRef.onerror = (e) => {
        URL.revokeObjectURL(audioUrl)
        audioRef = null
        reject(new Error('Blob Audio æ’­æ”¾å¤±è´¥'))
      }

      audioRef.play().catch((err) => {
        URL.revokeObjectURL(audioUrl)
        audioRef = null
        reject(err)
      })
    } catch (error) {
      reject(error)
    }
  })
}

/**
 * æ’­æ”¾æ–¹å¼ 2: ä½¿ç”¨ Data URL (å…¼å®¹æ€§æ›´å¥½)
 */
const playWithDataURL = async (audioBuffer, mimeType) => {
  return new Promise((resolve, reject) => {
    try {
      cleanup()

      // å°† ArrayBuffer è½¬æ¢ä¸º base64
      const uint8Array = new Uint8Array(audioBuffer)
      let binary = ''
      for (let i = 0; i < uint8Array.length; i++) {
        binary += String.fromCharCode(uint8Array[i])
      }
      const base64 = btoa(binary)
      const dataUrl = `data:${mimeType};base64,${base64}`

      audioRef = new Audio(dataUrl)
      audioRef.preload = 'auto'
      audioRef.setAttribute('webkit-playsinline', 'true')
      audioRef.setAttribute('playsinline', 'true')

      audioRef.onended = () => {
        audioRef = null
        resolve()
      }

      audioRef.onerror = () => {
        audioRef = null
        reject(new Error('Data URL Audio æ’­æ”¾å¤±è´¥'))
      }

      audioRef.play().catch(reject)
    } catch (error) {
      reject(error)
    }
  })
}

/**
 * æ’­æ”¾æ–¹å¼ 3: ä½¿ç”¨ HTML5 Audio å…ƒç´  (ç§»åŠ¨ç«¯å…¼å®¹æ€§æœ€å¥½)
 */
const playWithElement = async (audioBuffer, mimeType) => {
  return new Promise((resolve, reject) => {
    try {
      cleanup()

      // ç§»é™¤æ—§çš„ audio å…ƒç´ 
      const oldElement = document.getElementById('tts-audio-element')
      if (oldElement) {
        oldElement.remove()
      }

      // åˆ›å»ºæ–°çš„ audio å…ƒç´ 
      const audio = document.createElement('audio')
      audio.id = 'tts-audio-element'
      audio.style.display = 'none'

      // ä½¿ç”¨ Data URLï¼ˆæ›´å…¼å®¹ï¼‰
      const uint8Array = new Uint8Array(audioBuffer)
      let binary = ''
      for (let i = 0; i < uint8Array.length; i++) {
        binary += String.fromCharCode(uint8Array[i])
      }
      const base64 = btoa(binary)
      const dataUrl = `data:${mimeType};base64,${base64}`

      audio.src = dataUrl
      audio.preload = 'auto'

      // é‡è¦ï¼šè®¾ç½®ç§»åŠ¨ç«¯å…¼å®¹å±æ€§
      audio.setAttribute('webkit-playsinline', 'true')
      audio.setAttribute('playsinline', 'true')

      audio.onended = () => {
        audioElementRef = null
        resolve()
      }

      audio.onerror = (e) => {
        console.error('Audio å…ƒç´ æ’­æ”¾é”™è¯¯:', e)
        audioElementRef = null
        reject(new Error('Audio å…ƒç´ æ’­æ”¾å¤±è´¥'))
      }

      document.body.appendChild(audio)
      audioElementRef = audio

      // ä½¿ç”¨ play() æ–¹æ³•
      const playPromise = audio.play()

      if (playPromise !== undefined) {
        playPromise.catch((err) => {
          console.error('æ’­æ”¾è¢«æ‹’ç»:', err)
          audioElementRef = null
          reject(err)
        })
      }
    } catch (error) {
      reject(error)
    }
  })
}

/**
 * æ’­æ”¾æ–¹å¼ 4: æµè§ˆå™¨åŸç”Ÿ Web Speech API (ä½¿ç”¨ç§»åŠ¨ç«¯ä¿®å¤å™¨ï¼‰
 */
const playWithWebSpeechAPI = async (text) => {
  try {
    // åŠ¨æ€å¯¼å…¥ç§»åŠ¨ç«¯ä¿®å¤å™¨
    const { default: MobileSpeechFixer } = await import('./mobileSpeechFixer.js')
    const speechFixer = new MobileSpeechFixer()
    
    console.log('[TTS] ä½¿ç”¨ç§»åŠ¨ç«¯ä¿®å¤å™¨æ’­æ”¾:', text)
    
    // ä½¿ç”¨ç§»åŠ¨ç«¯ä¼˜åŒ–çš„è¯­éŸ³æ’­æ”¾
    const result = await speechFixer.speak(text, {
      lang: 'en-US',
      rate: 0.9,
      pitch: 1,
      volume: 1
    })
    
    console.log('[TTS] ç§»åŠ¨ç«¯è¯­éŸ³æ’­æ”¾å®Œæˆ')
    return result
    
  } catch (error) {
    console.error('[TTS] ç§»åŠ¨ç«¯ä¿®å¤å™¨å¤±è´¥:', error)
    
    // é™çº§åˆ°åŸºç¡€å®ç°
    return playWithBasicWebSpeechAPI(text)
  }
}

/**
 * åŸºç¡€ Web Speech API å®ç°ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
 */
const playWithBasicWebSpeechAPI = (text) => {
  return new Promise((resolve, reject) => {
    if (!('speechSynthesis' in window)) {
      reject(new Error('æµè§ˆå™¨ä¸æ”¯æŒ Web Speech API'))
      return
    }

    console.log('[TTS] ä½¿ç”¨åŸºç¡€ Web Speech API æ’­æ”¾:', text)

    // å–æ¶ˆå½“å‰æ’­æ”¾
    window.speechSynthesis.cancel()

    // ç¡®ä¿è¯­éŸ³æœåŠ¡å·²åˆå§‹åŒ–
    const voices = window.speechSynthesis.getVoices()
    if (voices.length === 0) {
      // æœ‰äº›æµè§ˆå™¨éœ€è¦ç­‰å¾… voices åŠ è½½
      setTimeout(() => {
        try {
          speakWithFallback(text, resolve, reject)
        } catch (error) {
          reject(error)
        }
      }, 100)
    } else {
      speakWithFallback(text, resolve, reject)
    }
  })
}

/**
 * å®é™…æ‰§è¡Œè¯­éŸ³æ’­æ”¾çš„å‡½æ•°ï¼ŒåŒ…å«è¯­éŸ³é€‰æ‹©fallback
 */
const speakWithFallback = (text, resolve, reject) => {
  const utterance = new SpeechSynthesisUtterance(text)
  
  // å°è¯•è®¾ç½®åˆé€‚çš„è‹±æ–‡è¯­éŸ³
  const voices = window.speechSynthesis.getVoices()
  const englishVoices = voices.filter(voice => 
    voice.lang.startsWith('en-') || 
    voice.lang.startsWith('en_')
  )
  
  if (englishVoices.length > 0) {
    // ä¼˜å…ˆä½¿ç”¨ç¾å¼è‹±è¯­
    const usVoice = englishVoices.find(voice => voice.lang.startsWith('en-US')) || englishVoices[0]
    utterance.voice = usVoice
    utterance.lang = usVoice.lang
    console.log('[TTS] é€‰æ‹©è¯­éŸ³:', usVoice.name, usVoice.lang)
  } else {
    // fallback åˆ°é»˜è®¤è®¾ç½®
    utterance.lang = 'en-US'
  }
  
  utterance.rate = 0.9
  utterance.pitch = 1
  utterance.volume = 1

  utterance.onend = () => {
    console.log('[TTS] Web Speech API æ’­æ”¾å®Œæˆ')
    resolve()
  }
  utterance.onerror = (e) => {
    console.error('[TTS] Web Speech API é”™è¯¯:', e)
    console.error('[TTS] é”™è¯¯è¯¦æƒ…:', e.error, e.message)
    reject(new Error('Web Speech API æ’­æ”¾å¤±è´¥: ' + (e.error || e.message)))
  }
  
  utterance.onstart = () => {
    console.log('[TTS] Web Speech API å¼€å§‹æ’­æ”¾')
  }

  // æ¸…é™¤ä¹‹å‰çš„è¯­éŸ³é˜Ÿåˆ—
  window.speechSynthesis.cancel()
  
  // æ·»åŠ çŸ­æš‚å»¶è¿Ÿç¡®ä¿æ¸…ç†å®Œæˆ
  setTimeout(() => {
    try {
      window.speechSynthesis.speak(utterance)
    } catch (error) {
      console.error('[TTS] speak è°ƒç”¨å¤±è´¥:', error)
      reject(error)
    }
  }, 50)
}

/**
 * é€šç”¨æ’­æ”¾å‡½æ•° - å°è¯•å¤šç§æ–¹å¼
 */
const playAudio = async (audioBuffer, mimeType = 'audio/mpeg') => {
  const errors = []

  if (caps.isMobile) {
    try {
      await playWithElement(audioBuffer, mimeType)
      return
    } catch (error) {
      errors.push(`Elementæ–¹å¼: ${error.message}`)
      console.log('Audio å…ƒç´ æ’­æ”¾å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ç§æ–¹å¼')
    }
  }

  // æ–¹å¼ 1: Blob URL (æœ€å¿«ï¼Œä½†å…¼å®¹æ€§å¯èƒ½æœ‰é—®é¢˜)
  if (!caps.isXiaomi) {
    try {
      await playWithBlob(audioBuffer, mimeType)
      return
    } catch (error) {
      errors.push(`Blobæ–¹å¼: ${error.message}`)
      console.log('Blob æ’­æ”¾å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ç§æ–¹å¼')
    }
  }

  // æ–¹å¼ 2: Data URL
  try {
    await playWithDataURL(audioBuffer, mimeType)
    return
  } catch (error) {
    errors.push(`DataURLæ–¹å¼: ${error.message}`)
    console.log('Data URL æ’­æ”¾å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ç§æ–¹å¼')
  }

  // æ–¹å¼ 3: HTML5 Audio å…ƒç´  (ç§»åŠ¨ç«¯å…¼å®¹æ€§æœ€å¥½)
  try {
    await playWithElement(audioBuffer, mimeType)
    return
  } catch (error) {
    errors.push(`Elementæ–¹å¼: ${error.message}`)
    console.log('Audio å…ƒç´ æ’­æ”¾å¤±è´¥')
  }

  // æ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥
  throw new Error(`æ‰€æœ‰æ’­æ”¾æ–¹å¼éƒ½å¤±è´¥: ${errors.join('; ')}`)
}

/**
 * æ’­æ”¾å•è¯å‘éŸ³
 */
export const playWordAudio = async (word, voiceType = 'US') => {
  console.log(`[TTS] æ’­æ”¾å•è¯: ${word}, æµè§ˆå™¨: ${caps.isAndroid ? 'Android' : 'Desktop'}${caps.isXiaomi ? ' (å°ç±³)' : ''}`)

  if (!word || typeof word !== 'string') {
    throw new Error('å•è¯å†…å®¹æ— æ•ˆ')
  }

  if (!audioUnlocked) {
    audioUnlocked = await unlockAudio()
  }

  const voice = voiceType === 'US' ? 'en-US-GuyNeural' : 'en-GB-SoniaNeural'

  try {
    const response = await fetch('/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text: word, voice })
    })

    if (response.status === 418) {
      // æœåŠ¡å™¨è¦æ±‚é™çº§åˆ° Web Speech API
      throw new Error('æœåŠ¡å™¨è¦æ±‚é™çº§åˆ° Web Speech API')
    }

    if (!response.ok) {
      throw new Error(`TTS è¯·æ±‚å¤±è´¥: ${response.status}`)
    }

    const arrayBuffer = await response.arrayBuffer()

    // å°ç±³è®¾å¤‡ä½¿ç”¨ audio/mpeg
    const mimeType = caps.isXiaomi ? 'audio/mpeg' : 'audio/mpeg'

    await playAudio(arrayBuffer, mimeType)
  } catch (error) {
    console.error('Edge TTS æ’­æ”¾å¤±è´¥ï¼Œå°è¯•é™çº§åˆ° Web Speech API:', error)

    // é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨æµè§ˆå™¨åŸç”Ÿ Web Speech API
    try {
      await playWithWebSpeechAPI(word)
      console.log('[TTS] Web Speech API æ’­æ”¾æˆåŠŸ')
    } catch (fallbackError) {
      console.error('Web Speech API ä¹Ÿå¤±è´¥äº†:', fallbackError)
      throw new Error(`è¯­éŸ³æ’­æ”¾å¤±è´¥: ${error.message}`)
    }
  }
}

/**
 * æ’­æ”¾å¥å­å‘éŸ³
 */
export const playSentenceAudio = async (sentence, voiceType = 'US') => {
  console.log(`[TTS] æ’­æ”¾å¥å­, æµè§ˆå™¨: ${caps.isAndroid ? 'Android' : 'Desktop'}${caps.isXiaomi ? ' (å°ç±³)' : ''}`)

  if (!sentence || typeof sentence !== 'string') {
    throw new Error('å¥å­å†…å®¹æ— æ•ˆ')
  }

  if (!audioUnlocked) {
    audioUnlocked = await unlockAudio()
  }

  const voice = 'en-US-SarahNeural'

  try {
    const response = await fetch('/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text: sentence, voice, rate: '-5%' })
    })

    if (response.status === 418) {
      // æœåŠ¡å™¨è¦æ±‚é™çº§åˆ° Web Speech API
      throw new Error('æœåŠ¡å™¨è¦æ±‚é™çº§åˆ° Web Speech API')
    }

    if (!response.ok) {
      throw new Error(`TTS è¯·æ±‚å¤±è´¥: ${response.status}`)
    }

    const arrayBuffer = await response.arrayBuffer()

    const mimeType = caps.isXiaomi ? 'audio/mpeg' : 'audio/mpeg'

    await playAudio(arrayBuffer, mimeType)
  } catch (error) {
    console.error('Edge TTS æ’­æ”¾å¤±è´¥ï¼Œå°è¯•é™çº§åˆ° Web Speech API:', error)

    // é™çº§æ–¹æ¡ˆ
    try {
      await playWithWebSpeechAPI(sentence)
      console.log('[TTS] Web Speech API æ’­æ”¾æˆåŠŸ')
    } catch (fallbackError) {
      console.error('Web Speech API ä¹Ÿå¤±è´¥äº†:', fallbackError)
      throw new Error(`è¯­éŸ³æ’­æ”¾å¤±è´¥: ${error.message}`)
    }
  }
}

/**
 * æ˜¾ç¤ºè¯­éŸ³ç³»ç»ŸçŠ¶æ€
 */
export const showSpeechStatus = () => {
  if ('speechSynthesis' in window) {
    const voices = window.speechSynthesis.getVoices()
    const englishVoices = voices.filter(v => 
      v.lang.startsWith('en-') || v.lang.startsWith('en_')
    )
    
    console.log('ğŸ¤ è¯­éŸ³ç³»ç»ŸçŠ¶æ€:', {
      totalVoices: voices.length,
      englishVoices: englishVoices.length,
      isSpeaking: window.speechSynthesis.speaking,
      pending: window.speechSynthesis.pending,
      paused: window.speechSynthesis.paused,
      userAgent: navigator.userAgent,
      platform: navigator.platform
    })
    
    // æ˜¾ç¤ºè‹±æ–‡è¯­éŸ³åˆ—è¡¨
    console.log('ğŸ”Š å¯ç”¨è‹±æ–‡è¯­éŸ³:')
    englishVoices.forEach((voice, index) => {
      console.log(`${index + 1}. ${voice.name} (${voice.lang}) - ${voice.localService ? 'Local' : 'Remote'}`)
    })
  } else {
    console.log('âŒ æµè§ˆå™¨ä¸æ”¯æŒ Web Speech API')
  }
}

/**
 * åœæ­¢æ’­æ”¾
 */
export const stopAudio = () => {
  cleanup()
  if ('speechSynthesis' in window) {
    window.speechSynthesis.cancel()
  }
}

/**
 * åˆå§‹åŒ–è¯­éŸ³å¼•æ“
 */
export const initSpeechEngine = async () => {
  console.log('[TTS] åˆå§‹åŒ–è¯­éŸ³å¼•æ“')
  console.log('[TTS] æµè§ˆå™¨èƒ½åŠ›:', caps)

  // é¢„åŠ è½½ Web Speech API (ç§»åŠ¨ç«¯éœ€è¦)
  if ('speechSynthesis' in window) {
    // Web Speech API éœ€è¦ç”¨æˆ·äº¤äº’æ‰èƒ½æ­£å¸¸å·¥ä½œ
    // å…ˆè·å–è¯­éŸ³åˆ—è¡¨æ¥åˆå§‹åŒ–
    const loadVoices = () => {
      const voices = window.speechSynthesis.getVoices()
      console.log('[TTS] å¯ç”¨è¯­éŸ³æ•°é‡:', voices.length)
      if (voices.length > 0) {
        const englishVoices = voices.filter(voice => 
          voice.lang.startsWith('en-') || voice.lang.startsWith('en_')
        )
        console.log('[TTS] è‹±æ–‡è¯­éŸ³æ•°é‡:', englishVoices.length)
      }
    }

    // ç«‹å³å°è¯•åŠ è½½
    loadVoices()
    
    // ç›‘å¬è¯­éŸ³åˆ—è¡¨å˜åŒ–äº‹ä»¶ï¼ˆæŸäº›æµè§ˆå™¨éœ€è¦ï¼‰
    if (window.speechSynthesis.onvoiceschanged !== undefined) {
      window.speechSynthesis.onvoiceschanged = loadVoices
    }
    
    // å¤‡ç”¨æ–¹æ¡ˆï¼šå®šæ—¶æ£€æŸ¥ï¼ˆé’ˆå¯¹æŸäº›æµè§ˆå™¨ï¼‰
    let attempts = 0
    const checkInterval = setInterval(() => {
      attempts++
      const voices = window.speechSynthesis.getVoices()
      if (voices.length > 0 || attempts > 10) {
        clearInterval(checkInterval)
        console.log('[TTS] è¯­éŸ³åˆ—è¡¨åŠ è½½å®Œæˆï¼Œå°è¯•æ¬¡æ•°:', attempts)
      }
    }, 100)
  }

  if (!audioUnlocked) {
    audioUnlocked = await unlockAudio()
  }

  return true
}

/**
 * æ£€æµ‹è¯­éŸ³æ”¯æŒçŠ¶æ€
 */
export const getSpeechStatus = () => {
  const hasWebSpeechAPI = 'speechSynthesis' in window

  return {
    supported: true,
    isMobile: caps.isMobile,
    isAndroid: caps.isAndroid,
    isXiaomi: caps.isXiaomi,
    hasWebSpeechAPI,
    message: caps.isXiaomi
      ? 'ä½¿ç”¨å¢å¼ºæ’­æ”¾æ¨¡å¼ + Web Speech API é™çº§'
      : 'ä½¿ç”¨ Edge TTS è¯­éŸ³åˆæˆ',
    canTry: true,
    capabilities: caps
  }
}
