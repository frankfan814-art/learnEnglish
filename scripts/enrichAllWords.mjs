#!/usr/bin/env node
/**
 * è‡ªåŠ¨æ‰¹é‡å¤„ç†æ‰€æœ‰å‰©ä½™å•è¯
 */

import fs from 'fs/promises'
import path from 'path'
import dotenv from 'dotenv'
import { fetch } from 'undici'

const rootDir = process.cwd()
const envPath = path.resolve(rootDir, '.env.local')
dotenv.config({ path: envPath })
dotenv.config()

const API_BASE = process.env.API_BASE || 'http://localhost:3001'
const DOUBAO_API_KEY = process.env.DOUBAO_API_KEY || process.env.VITE_DOUBAO_API_KEY || ''
const DOUBAO_ENDPOINT = process.env.DOUBAO_ENDPOINT || process.env.VITE_DOUBAO_ENDPOINT || 'https://ark.cn-beijing.volces.com/api/v3/chat/completions'
const DOUBAO_MODEL = process.env.DOUBAO_MODEL || process.env.VITE_DOUBAO_MODEL || 'ep-20260118094854-wd5pp'
const EXAMPLES_PER_WORD = Number(process.env.EXAMPLES_PER_WORD || 10)
const BATCH_SIZE = 1000  // æ¯æ‰¹å¤„ç†1000ä¸ª
const RETRY = Number(process.env.RETRY || 2)
const RETRY_DELAY = Number(process.env.RETRY_DELAY || 1500)

const WORDS_FILE = path.resolve(rootDir, 'src', 'data', 'filtered_words.json')
const OUTPUT_FILE = path.resolve(rootDir, 'src', 'data', 'words_with_examples.json')

const sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms))

const postJson = async (url, body) => {
  const response = await fetch(url, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(body)
  })

  if (!response.ok) {
    const text = await response.text()
    throw new Error(`HTTP ${response.status}: ${text}`)
  }

  return response.json()
}

const loadWords = async () => {
  const raw = await fs.readFile(WORDS_FILE, 'utf8')
  const data = JSON.parse(raw)
  return (data.words || []).map((item) => item.word).filter(Boolean)
}

const getProcessedWords = async () => {
  try {
    const raw = await fs.readFile(OUTPUT_FILE, 'utf8')
    const data = JSON.parse(raw)
    const words = Object.keys(data.words || {})
    console.log(`å·²å¤„ç† ${words.length} ä¸ªå•è¯`)
    return words
  } catch {
    return []
  }
}

const enrichWord = async (word) => {
  const payload = {
    word,
    provider: 'doubao',
    deepseek: {},
    ollama: {},
    doubao: {
      apiKey: DOUBAO_API_KEY,
      endpoint: DOUBAO_ENDPOINT,
      model: DOUBAO_MODEL
    }
  }

  const runWithRetry = async (fn, label) => {
    let lastError = null
    for (let attempt = 1; attempt <= RETRY + 1; attempt += 1) {
      try {
        return await fn()
      } catch (error) {
        lastError = error
        console.error(`  âŒ ${word} ${label} å¤±è´¥ (ç¬¬ ${attempt} æ¬¡): ${error.message}`)
        if (attempt <= RETRY) {
          await sleep(RETRY_DELAY)
        }
      }
    }
    throw lastError
  }

  const definitions = await runWithRetry(
    () => postJson(`${API_BASE}/api/definitions`, payload),
    'é‡Šä¹‰'
  )
  const examples = await runWithRetry(
    () => postJson(`${API_BASE}/api/examples`, { ...payload, count: EXAMPLES_PER_WORD }),
    'ä¾‹å¥'
  )

  return { definitions, examples }
}

const main = async () => {
  const allWords = await loadWords()
  const processedWords = await getProcessedWords()

  // æ‰¾å‡ºæœªå¤„ç†çš„å•è¯
  const remainingWords = allWords.filter(word => !processedWords.includes(word))

  console.log(`\nğŸ“Š ä»»åŠ¡ç»Ÿè®¡:`)
  console.log(`  æ€»å•è¯æ•°: ${allWords.length}`)
  console.log(`  å·²å¤„ç†: ${processedWords.length}`)
  console.log(`  å‰©ä½™: ${remainingWords.length}`)
  console.log(`\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†...\n`)

  let totalProcessed = 0
  let batchNum = 0

  // åˆ†æ‰¹å¤„ç†
  for (let i = 0; i < remainingWords.length; i += BATCH_SIZE) {
    batchNum++
    const batch = remainingWords.slice(i, i + BATCH_SIZE)
    const startIdx = i + processedWords.length

    console.log(`\nğŸ“¦ æ‰¹æ¬¡ #${batchNum}: å¤„ç†å•è¯ ${startIdx + 1}-${Math.min(startIdx + batch.length, allWords.length)} (å…± ${batch.length} ä¸ª)`)

    for (let j = 0; j < batch.length; j++) {
      const word = batch[j]
      const currentIdx = startIdx + j + 1

      console.log(`  [${currentIdx}/${allWords.length}] ${word}...`)

      try {
        await enrichWord(word)
        totalProcessed++
        console.log(`  âœ… ${word} å®Œæˆ (æ‰¹æ¬¡è¿›åº¦: ${j + 1}/${batch.length}, æ€»è¿›åº¦: ${totalProcessed}/${remainingWords.length})`)
      } catch (error) {
        console.error(`  âŒ ${word} å¤±è´¥: ${error.message}`)
      }

      // æ¯10ä¸ªå•è¯ä¼‘æ¯ä¸€ä¸‹
      if ((j + 1) % 10 === 0 && j < batch.length - 1) {
        await sleep(500)
      }
    }

    console.log(`\nâœ… æ‰¹æ¬¡ #${batchNum} å®Œæˆï¼`)
    console.log(`ğŸ“ˆ å½“å‰è¿›åº¦: ${totalProcessed}/${remainingWords.length} å‰©ä½™å•è¯`)
    console.log(`ğŸ“Š æ€»è¿›åº¦: ${processedWords.length + totalProcessed}/${allWords.length} (${((processedWords.length + totalProcessed) / allWords.length * 100).toFixed(2)}%)`)
  }

  console.log(`\nğŸ‰ å…¨éƒ¨å®Œæˆï¼`)
  console.log(`ğŸ“Š æœ€ç»ˆç»Ÿè®¡:`)
  console.log(`  æ€»å¤„ç†: ${totalProcessed} ä¸ªå•è¯`)
  console.log(`  æ€»è¿›åº¦: ${processedWords.length + totalProcessed}/${allWords.length}`)
  console.log(`  è¾“å‡ºæ–‡ä»¶: ${OUTPUT_FILE}`)
}

main().catch((error) => {
  console.error('âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥:', error)
  process.exit(1)
})
